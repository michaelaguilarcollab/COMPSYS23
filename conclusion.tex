\section{Conclusions and Future Work}

In this paper, we reviewed a set of experiments where we combined IOR, a storage benchmark, against HPL, a compute benchmark simulating a tightly coupled linear algebra application. We ran these benchmarks on a system with per-allocation BeeOND file system capabilities, which gives a user a private file system by running storage services on compute nodes alongside running applications. Our goal was to show whether heavy storage use could impact compute task performance.

We were able to show that, even for large compute jobs (128 nodes, 7168 cores) paired with a small number of I/O processes (1 node, 56 processes), there was significant impact to the HPL runtimes. In some cases, HPL runtime was increased by up to 52\%. Surprisingly, we were also able to measure a potential impact (up to 2.5\% on 64 nodes) from simply running BeeOND processes alongside HPL without any I/O traffic. Such a phenomenon indicates that running BeeOND daemons on dedicated cores is a reasonable strategy as job node counts increase.

This research has uncovered a large number of future research directions. While we have uncovered CPU-based performance impacts from I/O daemons, we did not receive clear results regarding impact of metadata services. This is likely because the IOR benchmark parameters we used did not heavily exercise the metadata facilities of BeeOND. We intend to design new experiments that will specifically exercise metadata operations. We also intend to explore user-controlled placement of BeeOND processes to mitigate compute performance impact.
